# Project Specification Document: FinScythe

**Version:** 1.1
**Date:** 21 October 2025

## Project Name: FinScythe

### Project Goal
To create a web application that analyzes and visualizes the "sentiment dissonance" between professional financial analysts and retail investors for a given stock ticker, providing AI-driven synthesis to highlight key market conflicts and opportunities.

---

## 1.0 Core Features (Minimum Viable Product)

*   **Ticker Input:** A primary search bar for the user to enter a publicly traded stock ticker (e.g., TSLA, GME, AAPL).
*   **Unified Data Visualization:** A single, interactive chart that plots historical price and volume data. This chart will be overlaid with three additional data series: historical analyst sentiment, historical retail (Reddit) sentiment, and a **sentiment-adjusted quantitative price prediction** generated by our backend model.
*   **Sentiment Dials:** Two prominent, real-time "dials" or gauges that display the current sentiment score (e.g., on a 1-10 scale) for both Analyst and Retail sentiment, clearly labeled as "Bearish" or "Bullish."
*   **AI Dissonance Analysis:** A dedicated section that displays a concise, AI-generated summary and **natural language prediction**. This summary will not just report the news but will specifically synthesize and explain the disagreement between the two sentiment groups, and provide an overall market outlook.

---

## 2.0 Technical Stack

This stack is chosen for rapid development, ease of use, and robust performance for a hackathon context.

### Frontend:
*   **Framework:** React 18+ (using Vite for near-instant project scaffolding and hot-reloading).
*   **Language:** TypeScript
*   **Styling:** Tailwind CSS for rapid, utility-first UI development.
*   **Charting Library:** Chart.js with the `react-chartjs-2` wrapper.
*   **HTTP Client:** Axios for making requests to our backend.

### Backend:
*   **Framework:** FastAPI
*   **Language:** Python
*   **Data Analysis:** Pandas for data manipulation and analysis, **Numpy for numerical operations, and Arch for GARCH modeling.**
*   **HTTP Client:** `requests` library.
*   **AI Client:** `google-generativeai` library.
*   **Environment:** `python-dotenv` to manage API keys.
*   **Server:** `uvicorn` to run the FastAPI app.

### External APIs:
*   **Financial Data:** Alpha Vantage (Free Tier).
*   **Sentiment Data (Analyst & Retail):** Finnhub (Free Tier).
*   **AI Synthesis:** Google Gemini API (Gemini Pro model).

---

## 3.0 System Architecture

The application will follow a standard client-server model.

1.  **Client (React App):** The user enters a ticker. On submission, the client makes a single API call to our backend: `GET /api/stock-data?ticker=TSLA`.
2.  **Server (Python/FastAPI):**
    *   The server receives the request and validates the ticker symbol.
    *   It initiates three parallel asynchronous calls to the external APIs:
        *   Alpha Vantage for historical price data.
        *   Finnhub for historical/current Analyst News Sentiment.
        *   Finnhub for historical/current Retail Reddit Sentiment.
    *   Once all data is retrieved, the server uses Pandas to structure and clean the data.
    *   **It then calculates historical volatility using a GARCH model and determines a baseline drift from historical returns.**
    *   **Based on the current Analyst and Retail sentiment scores, the server determines an "Overall Market Bias" (e.g., Strongly Bullish, Neutral, Strongly Bearish).**
    *   **This "Overall Market Bias" is used to adjust the baseline drift for the Monte Carlo simulation.**
    *   **A Monte Carlo simulation is then run using the GARCH-derived volatility and the sentiment-adjusted drift to generate a quantitative price prediction.**
    *   The server then formats a specific prompt using the latest sentiment scores, news headlines, and the **direction of the quantitative price prediction.**
    *   This prompt is sent to the Google Gemini API for the "dissonance analysis" and **natural language prediction.**
    *   The server then bundles all the data (prices, sentiments, **quantitative prediction**, AI summary) into a single JSON object.
3.  **Response:** The server sends the unified JSON object back to the client. The React app then parses this data and updates the state, causing the chart, dials, **quantitative prediction line**, and analysis text to render.

---

## 4.0 Backend API Endpoint Specification

*   **Endpoint:** `GET /api/stock-data`
*   **Query Parameter:** `ticker` (string, e.g., "TSLA")
*   **Successful Response (200 OK):** A JSON object with the following structure:

```json
{
  "priceData": {
    "labels": ["2025-10-20", "2025-10-21", ...],
    "prices": [150.5, 152.3, ...]
  },
  "analystSentimentData": {
    "currentScore": 3.2,
    "history": [3.5, 3.4, 3.2, ...]
  },
  "retailSentimentData": {
    "currentScore": 8.9,
    "history": [7.8, 8.5, 8.9, ...]
  },
  "quantitativePredictionData": {
    "labels": ["2025-10-22", "2025-10-23", ...],
    "prices": [153.0, 154.2, ...]
  },
  "sentimentBias": "Moderately Bullish",
  "aiSummary": {
    "dissonance": "The primary conflict is between analyst concerns over Q3 production numbers and retail excitement driven by a new product announcement.",
    "analystRisk": "Analysts see significant risk in the current supply chain challenges impacting delivery targets.",
    "retailOpportunity": "The retail crowd is focused on the long-term potential of the new 'Cyber-quad' creating a new market category.",
    "naturalLanguagePrediction": "Based on the strong retail sentiment and recent positive news, the stock is expected to see moderate upward momentum in the short term, despite analyst concerns."
  }
}
```

---

## 5.0 Workload Division (For a 2-Person Team)

*   **Developer A: Frontend Lead**
    *   **Responsibilities:**
        *   Set up the Vite + React + TypeScript project.
        *   Implement the entire UI using Tailwind CSS.
        *   Integrate Chart.js, **including the new quantitative prediction line.**
        *   Manage client-side state.
        *   Connect to the backend API endpoint.
        *   Focus on making the application look polished and responsive.

*   **Developer B: Backend & API Lead**
    *   **Responsibilities:**
        *   Set up the Python + FastAPI server.
        *   Acquire and manage all external API keys in a `.env` file.
        *   Write the logic for the `/api/stock-data` endpoint.
        *   Implement the parallel fetching and data transformation logic for Alpha Vantage and Finnhub APIs using the `requests` library.
        *   Use Pandas for any necessary data cleaning or manipulation.
        *   **Implement GARCH modeling for volatility estimation.**
        *   **Develop logic to determine "Overall Market Bias" from sentiment scores.**
        *   **Implement Monte Carlo simulation with sentiment-adjusted drift for quantitative price prediction.**
        *   Engineer the prompt for the Google Gemini API, **including feeding in the quantitative prediction's direction.**
        *   Thoroughly test the endpoint.
        *   Deploy the backend (e.g., using Render or Vercel Serverless Functions).

---

## 6.0 Project Timeline & Execution Plan (24 Hours)

*   **Phase 1: Setup & Scaffolding (Hours 0-2)**
    *   **Both:** Agree on this spec.
    *   **Dev A (Frontend):** Initialize Vite project, install dependencies. Build a static, non-functional UI layout.
    *   **Dev B (Backend):** Initialize FastAPI project, install dependencies (`fastapi`, `uvicorn`, `requests`, `pandas`, `python-dotenv`, `google-generativeai`). Set up a mock `/api/stock-data` endpoint.

*   **Phase 2: Core Logic & Parallel Development (Hours 2-10)**
    *   **Dev A (Frontend):** Connect the UI to the mock backend endpoint.
    *   **Dev B (Backend):** Implement the real API fetching logic for Alpha Vantage and Finnhub. **Begin GARCH modeling and Monte Carlo simulation setup.**

*   **Phase 3: Quantitative Model & AI Integration (Hours 10-14)**
    *   **Dev B (Backend):** Finalize GARCH modeling, implement sentiment-based drift adjustment, and complete the Monte Carlo simulation. Focus on Google Gemini integration, fine-tuning the prompt to include quantitative prediction direction. Finalize the complete, working endpoint.

*   **Phase 4: Integration & Debugging (Hours 14-19)**
    *   **Both:** Switch from the mock endpoint to the live backend endpoint and debug any issues.

*   **Phase 5: Polish & Refinement (Hours 19-22)**
    *   **Dev A (Frontend):** Add loading spinners, error messages, and subtle animations.
    *   **Dev B (Backend):** Add error handling and implement basic caching.

*   **Phase 6: Pitch Preparation & Buffer (Hours 22-24)**
    *   **Both:** Stop coding. Prepare a demo script and practice the pitch.

---

## 7.0 Risk Assessment & Mitigation

*   **Risk:** External API rate limits are hit.
    *   **Mitigation:** Implement simple in-memory caching on the backend.
*   **Risk:** An API is down or returns unexpected data.
    *   **Mitigation:** The backend should have `try...except` blocks for each API call.
*   **Risk:** Google Gemini prompt yields poor results.
    *   **Mitigation:** Pre-write a very specific, structured prompt.
*   **Risk:** Time-consuming integration issues.
    *   **Mitigation:** Sticking rigidly to the API Endpoint Specification is the best defense.
